% %%
% Created 10 Jan 2011
% Last updated 18 Jan 2011
% tn248@cam.ac.uk
% %%

% Because I forget:
% Sweave("spa2_tn248", driver = cacheSweaveDriver)

\documentclass[9pt, oneside, reqno]{article}
\usepackage{amssymb, amsthm, amsmath, amsfonts}
\usepackage{fullpage}
\usepackage[tableposition=top]{caption}
\usepackage{ifthen}
\usepackage{listings}
\usepackage{graphicx}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}

\setlength{\textheight}{9truein}
\setlength{\topmargin}{-.5truein}
\setlength{\headheight}{0truein}
\setlength{\headsep}{0truein}

%\hwinfo{Thomson Nguyen}{Course}{01/01/2010}{Snazzy title}
\newcommand{\hwinfo}[4]{\hfill\hfill #1 \par
\hfill\hfill #2 \par
\hfill\hfill #3 \par
\par\bigskip
\begin{center}
\large	#4
\end{center}
}

\newcommand{\ans}[1]{\begin{proof}[{\bf #1}]}
\newcommand{\eans}{\end{proof}}
\theoremstyle{plain}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

% Euler for math | Palatino for rm | Helvetica for ss | Courier for tt
\renewcommand{\rmdefault}{ppl} % rm
\linespread{1.05}  % Palatino needs more leading
\usepackage[scaled]{helvet} % ss
\usepackage{courier} % tt
\usepackage{eulervm} 
\usepackage{color}

\lstloadlanguages{R}
\lstdefinelanguage{Renhanced}[]{R}{%
  morekeywords={acf,ar,arima,arima.sim,colMeans,colSums,is.na,is.null, mapply,ms,na.rm,nlmin,replicate,row.names,rowMeans,rowSums,seasonal, sys.time,system.time,ts.plot,which.max,which.min},
  deletekeywords={c},
  alsoletter={.\%},
  alsoother={:_\$}}
\lstset{language=Renhanced,extendedchars=true,
  basicstyle=\small\ttfamily,
  commentstyle=\textsl,
  keywordstyle=\mdseries,
 showstringspaces=false,
  index=[1][keywords], 
  indexstyle=\indexfonction}
\newcommand{\indexfonction}[1]{\index{#1@\texttt{#1}}}

\newenvironment{enumalph}{\begin{enumerate}\renewcommand{\labelenumi}{\textnormal{(\alph{enumi})}}}{\end{enumerate}}

 % I like comments

\begin{document}
\normalfont
\setkeys{Gin}{width=3.5in} % How big do we want our R figures?

\hwinfo{Thomson Nguyen (tn248)}{Scientific Programming (SP)}{\today}{Scientific Programming\\Assignment 3}

%\tableofcontents

\section*{Part I: Building the $d_{\textrm{min}}$ model}

\ans{Answer}
We would like to simulate 2d spatial point patterns using a $d_{\textrm{min}}$ model. In this model, each point has a circular exclusion zone with some radius drawn from a normal distribution with mean $m$ and standard deviation $s$. Points are added one at a time to some rectangular region $A$. Our function {\tt dmin2d} takes eight parameters: the number of points to simulate, the mean of our Normal distribution to sample from, the standard deviation, the possible range of $x$ values (low/high), the possible range of $y$ values (low/high), and whether we want the output plots or not (default set to on):

\begin{lstlisting}
	dmin2d <- function(n, m, s, xlo, xhi, ylo, yhi, plots=TRUE)
\end{lstlisting}

The code for our implementation can be found in the Appendix. Let's run a sample dispersion of 200 points in a 800 x 800 square region:

\begin{lstlisting}
> dmin2d(200,30,5,200,1000,100,900)
\end{lstlisting}

\begin{figure}[ht]
\begin{center}
\includegraphics{1.png}
\caption{Sample pattern generated from {\tt dmin2d(200,30,5,200,1000,100,900)}. }
\end{center}
\end{figure}

Finally, we'll note that our model is stochastic--all of the patterns generated are pseudo-random. If we ran it again, we'd get a different pattern entirely:

\begin{lstlisting}
> dmin2d(200,30,5,200,1000,100,900)
\end{lstlisting}

\begin{figure}[ht]
\begin{center}
\includegraphics{2.png}
\caption{Another sample pattern from {\tt dmin2d(200,30,5,200,1000,100,900)}. }
\end{center}
\end{figure}

\eans

\section*{Evaluating regularity index}

\ans{Answer}
Say we now wanted to compare this generated sample to some real data--maybe we have a 2d map of a forest, or a cross-section of some neural tissue. We could visually compare our sample to the map generated by the real data, or we could use something more quantitative. In 1978, W\"{a}ssle and Riemann \cite{wassle78} introduced a method of taking the ratio between the mean and standard deviation of the nearest-neighbour distances as a way of measuring mosaic regularity. This measure is (not surprisingly) called the {\bf regularity index} (RI). In our case, the higher the RI, the more regular the spatial distribution of our points \cite{eglen05}.

In our implementation, the function {\tt regind} takes in a dataframe of points outputted from {\tt dmin2d}, and whether we want a histogram of nearest-neighbour distances. It will then calculate the regularity index and output the histogram, if asked for:

\begin{lstlisting}
> res <- dmin2d(200,30,5,200,1000,100,900)
> regind(res,TRUE)
[1] 3.392006
\end{lstlisting}

\begin{figure}[ht]
\begin{center}
\includegraphics[width=3.2in]{2.png}
\includegraphics[width=3.2in]{2hist.png}
\caption{The spatial pattern from Figure 2 and its associated nearest-neighbour histogram.}
\end{center}
\end{figure}

The assignment states that the theoretical expectation for the RI for a set of points randomly positioned with no minimal distance constraint is around $1.91$. We will now attempt to replicate this result. Let's generate $1000$ patterns of $200$ points with no minimal distance constraint and calculate the RI for each:

\begin{lstlisting}
> theoretical <- replicate(1000,regind(dmin2d(200,0,0,0,1000,0,1000,FALSE)))
> theoretical <- theoretical[rev(order(theoretical))]
> theoretical[50]
[1] 2.057733
\end{lstlisting}

Here, {\tt theoretical} contains the RIs for all $1000$ simulations. We've sorted them and taken the 50th largest value. REASON ABOUT 50TH GOES HERE

What if we made the region a rectangle?

\begin{lstlisting}
> theoreticalrect <- replicate(1000,regind(dmin2d(200,0,0,0,500,0,2000,FALSE)))
> theoreticalrect <- theoreticalrect[rev(order(theoreticalrect))]
> theoreticalrect[50]
[1] 2.048001
\end{lstlisting}

We see the RI stays relatively the same. And if we halved the points twice?

\begin{lstlisting}
> theoreticalhalf <- replicate(1000,regind(dmin2d(100,0,0,0,1000,0,1000,FALSE)))
> theoreticalhalf <- theoreticalhalf[rev(order(theoreticalhalf))]
> theoretical[50]
[1] 2.150527
> theoreticalhalf2 <- replicate(1000,regind(dmin2d(50,0,0,0,1000,0,1000,FALSE)))
> theoreticalhalf2 <- theoreticalhalf2[rev(order(theoreticalhalf2))]
> theoreticalhalf2[50]
[1] 2.367768
\end{lstlisting}

We see that the RI increases as we decrease the number of points to simulate.

\eans

\section*{Fit the model to some data}

\ans{Answer}

We now have a real data file, {\tt spa3\_real.dat} that contains the $x,y$ locations of 238 points sampled in a $400 \times 400 \mu m^2$ grid. We want to see which possible values of $m,s$ in our $d_{\rm min}$ model can generate patterns similar to our real data file. 

\begin{figure}[ht]
\begin{center}
\includegraphics{real.png}
\caption{Spatial pattern of {\tt spa3\_real.dat}.}
\end{center}
\end{figure}

Our function, {\tt fitfinder}, takes in $m,s$ values and simulates ninety-nine 238-point patterns with those values. It then calculates the RI of each pattern (as well as the real dataset) and calculates a $u_i$ score for each pattern; if the RI of the real pattern is $x_1$ and the RI of the simulated patterns are $x_2,\ldots,x_{99}$, then for each pattern $x_i$ our $u_i$ score is

\[ u_i = \left | x_i - \frac{\sum_{j\neq i} x_i}{99} \right|.\]

The u-score measures the absolute difference between the RI our given pattern and the RI averages of the others. Our method of taking one pattern out comparing it against the others is known as a leave-one-out cross-validation. 

When trying to find a suitable pair of $m,s$ values, I decided to take a look at the RI of the real dataset:

\begin{lstlisting}
> regind(real)
[1] 4.203121
\end{lstlisting}

To start, I started with a low average to see what would happen:

\begin{lstlisting}
> summary(fitfinder(5,1,real))
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
0.002839 0.050220 0.107900 0.153500 0.204800 2.162000
\end{lstlisting}

Not promising--the max value is surely $u_1$. Let's try increasing the mean by a little bit:

\begin{lstlisting}
> summary(fitfinder(7,1,real))
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
0.003009 0.057530 0.141400 0.163700 0.204100 2.036000
\end{lstlisting}

Our $u_1$ value decreases while the mean of the others increase. After many, many tries, I tried $(18,4)$:

\begin{lstlisting}
> summary(fitfinder(18,4,real))
    Min.  1st Qu.   Median    Mean  3rd Qu.    Max. 
0.15845  0.163544 0.174400 0.180400 0.18542 0.19545
\end{lstlisting}

This looks promising--the spread between RIs is a bit smaller. Let's take a look at a sample $d_{min}$:

\begin{figure}[ht]
\begin{center}
\includegraphics[width=3in]{real.png}
\includegraphics[width=3in]{pros.png}
\caption{Visual comparison of {\tt spa3\_real.dat} vs {\tt dmin(238,18,4)}.}
\end{center}
\end{figure}

What's the RI of this pattern?

\begin{lstlisting}
> prospective <- dmin(238,18,4,0,400,0,400)
> regind(prospective)
[1] 4.19529
\end{lstlisting}

Compare to $4.203121$. It looks like $m=18$ and $s=4$ are good values. 
\eans


\appendix
\section*{Appendix: Code}

\begin{lstlisting}[language=Renhanced]
rm(list=ls())

dmin2d <- function(n, m, s, xlo, xhi, ylo, yhi, plots=TRUE){
	## Models a spacial pattern according 
	## to the following parameters:
	##
	## n: number of points to simulate
	## m: mean of Normal distribution
	## s: s.d. of Normal distribution
	## xlo, xhi: possible range of X values.
	## ylo, yhi: possible range of Y values.
	## plots: bool for whether to create plots
	## (I added this so part II would run faster)

	## first point initialisation
	thegoodones <- c(runif(1, xlo, xhi),runif(1,ylo,yhi)) 

	while(length(thegoodones) < n * 2){
	  trialpoint <- c(runif(1, xlo, xhi),runif(1,ylo,yhi))
	  exclusionmin <- max(0, rnorm(1,m,s))
	  if(min(dist(rbind(thegoodones,trialpoint))) > exclusionmin)
	     {thegoodones <- rbind(thegoodones,trialpoint)}
	}

	if(plots==TRUE){
	plot(c(xlo-round(xlo*.05),xhi), c(ylo-round(xlo*.05), yhi), 
		type = "n", xlab="", ylab="",main=paste("dmin(",
		paste(n,m,s,xlo,xhi,ylo,yhi,sep=", "),")",sep=""))
	rect(xlo,ylo,xhi,yhi,lty=2)
	points(thegoodones[,1],thegoodones[,2],pch=19)
	  }

	rownames(thegoodones) <- NULL
	return(thegoodones)
	}

regind <- function(pointsdata,hist=TRUE){
	## Takes a dataframe of points and calculates
	## the regularity index.
	##
	## pointsdata: a two-column df of points

	mins <- NULL

	distmat <- as.matrix(dist(pointsdata))
	diag(distmat) <- Inf
	for(i in 1:dim(pointsdata)[1]){
	mins <- c(mins,min(distmat[,i]))
		}
		
	if(hist==TRUE){
		hist(mins,xlab="Distance")
		}
	return(mean(mins)/sd(mins))
}

# PART I
res <- dmin2d(200,30,5,200,1000,100,900)

# PART II

# square
theoretical <- replicate(1000,regind(dmin2d(200,0,0,0,1000,0,1000,FALSE)))
theoretical <- theoretical[rev(order(theoretical))]
theoretical[50]

# rectangle
theoreticalrect <- replicate(1000,regind(dmin2d(200,0,0,0,500,0,2000,FALSE)))
theoreticalrect <- theoreticalrect[rev(order(theoreticalrect))]
theoreticalrect[50]

# half points
theoreticalhalf <- replicate(1000,regind(dmin2d(100,0,0,0,1000,0,1000,FALSE)))
theoreticalhalf <- theoreticalhalf[rev(order(theoreticalhalf))]
theoreticalhalf[50]

theoreticalhalf2 <- replicate(1000,regind(dmin2d(50,0,0,0,1000,0,1000,FALSE)))
theoreticalhalf2 <- theoreticalhalf2[rev(order(theoreticalhalf2))]
theoreticalhalf2[50]

# more points
theoreticalmore <- replicate(1000,regind(dmin2d(3,0,0,0,1000,0,1000,FALSE)))
theoreticalmore <- theoreticalmore[rev(order(theoreticalmore))]
theoreticalmore[50]

# PART III

## load the real data
real <- read.table("spa3_real.dat")
plot(c(0,400), c(0,400), 
		type = "n", xlab="", ylab="",main="Real Data")
rect(0,0,400,400,lty=2)	
points(real[,1],real[,2],pch=19)

fitfinder <- function(m,s,real){
	## calculates u-score for a given set of m,s parameters.
	## n=238, xlo,ylo = 0, xhi,yhi = 400
	## real= real dataset
	uscore <- NULL
	ffsimulated <- replicate(99,regind(dmin2d(238,m,s,0,400,0,400,FALSE)))
	rri <- regind(real)
	ris <- c(rri,ffsimulated)
	
	for(i in 1:100){
		currentri <- ris[i]
		ristemp <- ris[-i]
		uscore[i] <- abs(currentri - sum(ristemp)/99)
	}
	return(uscore)
}
\end{lstlisting}
\begin{thebibliography}{}
    \bibitem{wassle78}
	W\"{a}ssle, H. \& Riemann, H.J. 1978 The mosaic of nerve cells in the mammalian retina. Proc. R. Soc. Lond. B Biol. Sci., 200, 441 461.
	
	\bibitem{eglen05}
	Kronhaus, D.M. \& Eglen, S.J. The Role of Simplifying Models in Neuroscience: Modelling Structure and Function. Bio-Inspired Computing and Communication, 2008.
   

\end{thebibliography}

\end{document}
